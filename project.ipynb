{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           13871\n",
       "candidate                    13775\n",
       "candidate_confidence         13871\n",
       "relevant_yn                  13871\n",
       "relevant_yn_confidence       13871\n",
       "sentiment                    13871\n",
       "sentiment_confidence         13871\n",
       "subject_matter               13545\n",
       "subject_matter_confidence    13871\n",
       "candidate_gold                  28\n",
       "name                         13871\n",
       "relevant_yn_gold                32\n",
       "retweet_count                13871\n",
       "sentiment_gold                  15\n",
       "subject_matter_gold             18\n",
       "text                         13871\n",
       "tweet_coord                     21\n",
       "tweet_created                13871\n",
       "tweet_id                     13871\n",
       "tweet_location                9959\n",
       "user_timezone                 9468\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab \n",
    "import nltk\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "\n",
    "#read csv into dataframe\n",
    "GOPSentiDf = pd.read_csv('2016GOPPresDebSenti.csv')\n",
    "AirlineSentiDf = pd.read_csv('TweetsUSAirlineSenti.csv')\n",
    "\n",
    "#Begin feature removal\n",
    "GOPSentiDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        14640\n",
       "airline_sentiment               14640\n",
       "airline_sentiment_confidence    14640\n",
       "negativereason                   9178\n",
       "negativereason_confidence       10522\n",
       "airline                         14640\n",
       "airline_sentiment_gold             40\n",
       "name                            14640\n",
       "negativereason_gold                32\n",
       "retweet_count                   14640\n",
       "text                            14640\n",
       "tweet_coord                      1019\n",
       "tweet_created                   14640\n",
       "tweet_location                   9907\n",
       "user_timezone                    9820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AirlineSentiDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed unnecessary columns\n"
     ]
    }
   ],
   "source": [
    "#we want the sentiment analysis to be as general as possible, independent of user location, when they tweeted, \n",
    "#the tweet's subject matter, how often their tweets get retweeted, who is the user, \n",
    "\n",
    "GOPSentiDf.drop('user_timezone', 1, inplace = True)\n",
    "GOPSentiDf.drop('tweet_location', 1, inplace = True)\n",
    "GOPSentiDf.drop('tweet_id', 1, inplace = True)\n",
    "GOPSentiDf.drop('tweet_created', 1, inplace = True)\n",
    "GOPSentiDf.drop('tweet_coord', 1, inplace = True)\n",
    "#subject matter gold is the specific topic of tweeted text, such as Religion, Abortion, Immigration, FOX news, etc.\n",
    "GOPSentiDf.drop('subject_matter_gold', 1, inplace = True)\n",
    "#sentiment gold is repetitive of the sentiment column\n",
    "GOPSentiDf.drop('sentiment_gold', 1, inplace = True)\n",
    "GOPSentiDf.drop('retweet_count', 1, inplace = True)\n",
    "#relevant_yn_gold is repetitive of relevant\n",
    "GOPSentiDf.drop('relevant_yn_gold', 1, inplace = True)\n",
    "GOPSentiDf.drop('name', 1, inplace = True)\n",
    "#candidate_gold is repetitive of candidate\n",
    "GOPSentiDf.drop('candidate_gold', 1, inplace = True)\n",
    "GOPSentiDf.drop('subject_matter_confidence', 1, inplace = True)\n",
    "GOPSentiDf.drop('subject_matter', 1, inplace = True)\n",
    "GOPSentiDf.drop('relevant_yn_confidence', 1, inplace = True)\n",
    "GOPSentiDf.drop('relevant_yn', 1, inplace = True)\n",
    "GOPSentiDf.drop('candidate_confidence', 1, inplace = True)\n",
    "GOPSentiDf.drop('candidate', 1, inplace = True)\n",
    "\n",
    "#we want to do the same for the tweets for the US Airlines\n",
    "AirlineSentiDf.drop('user_timezone', 1, inplace = True)\n",
    "AirlineSentiDf.drop('tweet_location', 1, inplace = True)\n",
    "AirlineSentiDf.drop('tweet_created', 1, inplace = True)\n",
    "AirlineSentiDf.drop('tweet_coord', 1, inplace = True)\n",
    "AirlineSentiDf.drop('retweet_count', 1, inplace = True)\n",
    "AirlineSentiDf.drop('negativereason_gold', 1, inplace = True)\n",
    "AirlineSentiDf.drop('name', 1, inplace = True)\n",
    "AirlineSentiDf.drop('airline_sentiment_gold', 1, inplace = True)\n",
    "AirlineSentiDf.drop('airline', 1, inplace = True)\n",
    "AirlineSentiDf.drop('negativereason_confidence', 1, inplace = True)\n",
    "AirlineSentiDf.drop('negativereason', 1, inplace = True)\n",
    "\n",
    "print(\"removed unnecessary columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      13871\n",
       "sentiment               13871\n",
       "sentiment_confidence    13871\n",
       "text                    13871\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOPSentiDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                        14640\n",
       "airline_sentiment               14640\n",
       "airline_sentiment_confidence    14640\n",
       "text                            14640\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AirlineSentiDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created emoticons comparator\n"
     ]
    }
   ],
   "source": [
    "#list of emotions, not emojis\n",
    "#create 2d array with 50 columns and 3 rows, where the row determines the number of character per emoji\n",
    "#i.e., :) contains 2 characters so it belongs it row 0, while :-D goes to row 1, and so on\n",
    "PosEmoAr = [[':)', ':]', ':}', '=)', '=]', '=}', ':B', '=B', '<3', '^^', ':*', '=*', ';)', ';]', \n",
    "             ';}', '=P', '=p', ':P', ':p', ':b', '=b'], \n",
    "            [':o)', ':o]', ':o}', ':-]', ':-)', ':-}', '=^]', '=^)', '=^}', ':-D', ':-B', \n",
    "             ':^D', ':^B', '=^B', '=^D', ':\\')', ':\\']', '=\\'}', '^.^', '^-^', '^_^', ':-*', \n",
    "             ':-p', ':-P', ':-b', ':^p', ':^P', ':^b', '\\\\o\\\\', '/o/', '=^p', '=^P', '=^b', '\\\\o/']]\n",
    "NegEmoAr = [['D:', 'D=', ':(', ':[', ':{', '=(', '=[', '={', '=\\\\', ':\\\\', '=/', ':/', '=$', 'Oo'], \n",
    "            ['D-:', 'D^:', 'D^=', ':o(', ':o[', ':^(', ':^[', ':^{', '=^(', '=^{', '>=(', '>=[', '>={', \n",
    "             ':-[', ':-(', '=^[', '>=[', ':\\'(', ':\\'[', ':\\'{', '=\\'{', '=\\'(', '=\\'[', 'o.O', 'O_o', ':o{'],\n",
    "            ['>:-{', '>:-[', '>:-(', '>=^[', '>=^(', '>:-{', '>=^{'],\n",
    "            ['>:-=(', ':$:-{']]\n",
    "NeuEmoAr = [[':|', '=|', '><', ':o', ':O', '=0', ':@', '=@', ':x', '=X', ':#', '=#'], \n",
    "            [':-|', '>.<', '>_<', ':^o', ':^@', '-.-', '-_-', ':-x', ':-X', ':-@', ':-#', ':^x', ':^#'], \n",
    "            ['-.-\\'', '-_-\\'']]\n",
    "\n",
    "print(\"created emoticons comparator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created new features\n"
     ]
    }
   ],
   "source": [
    "#create features: number of negative and positive words and emoticons, number of emoticons\n",
    "GOPTxtAr = GOPSentiDf.values[0:,][:,3]\n",
    "GOPNumPosAr = []\n",
    "GOPNumNegAr = []\n",
    "GOPNumEmoAr = []\n",
    "for i in range(len(GOPTxtAr)):\n",
    "    GOPNumPosAr.append(0)\n",
    "    GOPNumNegAr.append(0)\n",
    "    GOPNumEmoAr.append(0)\n",
    "    \n",
    "AirTxtAr = AirlineSentiDf.values[0:,][:,3]\n",
    "AirNumPosAr = []\n",
    "AirNumNegAr = []\n",
    "AirNumEmoAr = []\n",
    "\n",
    "for i in range(len(AirTxtAr)):\n",
    "    AirNumPosAr.append(0)\n",
    "    AirNumNegAr.append(0)\n",
    "    AirNumEmoAr.append(0)\n",
    "\n",
    "print(\"created new features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all stopwords, hashtags, web links, retweets (RT), and direct @s\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "index = 0\n",
    "shrtTxtGOPAr = []\n",
    "for i in range(len(GOPTxtAr)):\n",
    "    shrtTxtGOPAr.append('')\n",
    "for text in GOPTxtAr:\n",
    "    GOPTxtAr[index] = GOPTxtAr[index].replace('RT ', '')\n",
    "    while (GOPTxtAr[index].find('#') != -1):\n",
    "        GOPTxtAr[index] = GOPTxtAr[index].replace(GOPTxtAr[index][GOPTxtAr[index].find('#') : GOPTxtAr[index].find(' ', GOPTxtAr[index].find('#'))], '')\n",
    "    while (GOPTxtAr[index].find('@') != -1):\n",
    "        GOPTxtAr[index] = GOPTxtAr[index].replace(GOPTxtAr[index][GOPTxtAr[index].find('@') : GOPTxtAr[index].find(' ', GOPTxtAr[index].find('@'))], '')\n",
    "    while (GOPTxtAr[index].find('http') != -1):\n",
    "        GOPTxtAr[index] = GOPTxtAr[index].replace(GOPTxtAr[index][GOPTxtAr[index].find('http') : ], '')\n",
    "    text = GOPTxtAr[index]\n",
    "    GOPTxtAr[index] = ''\n",
    "    words = word_tokenize(text)\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            shrtTxtGOPAr[index] = shrtTxtGOPAr[index] + ' ' + w\n",
    "    GOPTxtAr[index] = shrtTxtGOPAr[index]\n",
    "    index += 1\n",
    "\n",
    "index = 0\n",
    "shrtTxtAirAr = []\n",
    "for i in range(len(AirTxtAr)):\n",
    "    shrtTxtAirAr.append('')\n",
    "for text in AirTxtAr:\n",
    "    AirTxtAr[index] = AirTxtAr[index].replace('RT ', '')\n",
    "    while (AirTxtAr[index].find('#') != -1):\n",
    "        AirTxtAr[index] = AirTxtAr[index].replace(AirTxtAr[index][AirTxtAr[index].find('#') : AirTxtAr[index].find(' ', AirTxtAr[index].find('#'))], '')\n",
    "    while (GOPTxtAr[index].find('@') != -1):\n",
    "        AirTxtAr[index] = AirTxtAr[index].replace(AirTxtAr[index][AirTxtAr[index].find('@') : AirTxtAr[index].find(' ', AirTxtAr[index].find('@'))], '')\n",
    "    while (GOPTxtAr[index].find('http') != -1):\n",
    "        AirTxtAr[index] = AirTxtAr[index].replace(AirTxtAr[index][AirTxtAr[index].find('http') : ], '')\n",
    "    text = AirTxtAr[index]\n",
    "    AirTxtAr[index] = ''\n",
    "    words = word_tokenize(text)\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            shrtTxtAirAr[index] = shrtTxtAirAr[index] + ' ' + w\n",
    "    AirTxtAr[index] = shrtTxtAirAr[index]\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
